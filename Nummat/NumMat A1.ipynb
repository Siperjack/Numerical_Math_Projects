{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TMA4215 Numerisk Matematikk \n",
    "\n",
    "Høst 2021 – August 27, 2021\n",
    "\n",
    "R. Bergmann, E. Çokaj, O. P. Hellan \n",
    "\n",
    "# Problem Sheet 1\n",
    "\n",
    "## Deadline\n",
    "September 5, 2021, 23:59\n",
    "\n",
    "\n",
    "## Submission\n",
    "submit your Jupyter notebook containing the solution via upload in blackboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.\n",
    "\n",
    "Let $A\\in \\mathbb R^{n\\times n}$ be an invertible matrix and $b\\in\\mathbb R^n$ be given.\n",
    "    Consider the problem of solving the linear system of equations “Find $x\\in \\mathbb R^n$ such that $Ax=b$”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Suppose we find $x$ with an error $\\delta x$ due to an error in $b$ of size $\\delta b$. This means we actually solved\n",
    "   $$ A(x+\\delta x) = b + \\delta b$$\n",
    "   Derive upper bounds for the absolute condition number $\\frac{\\lVert \\delta x \\rVert}{\\lVert\\delta b\\rVert} \\leq K_{\\mathrm{abs}}(b)$\n",
    "   and the relative condition number $\\frac{\\lVert\\delta x \\rVert / \\lVert x\\rVert}{\\lVert \\delta b\\rVert / \\lVert b \\rVert } \\leq K(b)$ for the case of the $2$-norm in terms of the Eigenvalues of $A$.\n",
    "\n",
    "   Main ingredients are the $2$-norm of a vector, the (compatible, induced) $2$-norm (or spectral norm) of a matrix and their compatibility, i.e. that $\\lVert Ax\\rVert_2 \\leq \\lVert A\\rVert_2 \\lVert x\\rVert_2$ holds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Let further $A$ be disturbed data, i. e. we have a disturbed solution $x+\\delta x$ often\n",
    "   $$\n",
    "   (A+\\delta A)(x+\\delta x) = b+\\delta b\n",
    "   $$\n",
    "   How does the relative error $\\frac{\\lVert \\delta x \\rVert}{\\lVert x \\rVert}$ depend on the two relative errors $\\frac{\\lVert \\delta b \\rVert}{\\lVert b \\rVert}$ and $\\frac{\\lVert \\delta A \\rVert}{\\lVert a \\rVert}$ of the data?\n",
    "\n",
    "3. What can you say **a priori** (before you solve any system) about relative errors when\n",
    "$$\n",
    "  Ax = \\begin{pmatrix}\n",
    "  1 & 1\\\\\n",
    "  1.0004 & 1\n",
    "  \\end{pmatrix}x\n",
    "  = \\begin{pmatrix}\n",
    "    2\\\\2\n",
    "  \\end{pmatrix} = b\n",
    "$$\n",
    "  is given (you can use Python to reason for your answer)?\n",
    "  Compute the exact solution by hand and use `Python` to solve the disturbed version with $\\delta b = \\begin{pmatrix} 2\\\\2.001 \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Solutions 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)\n",
    "\n",
    "Firs of all we got $ Ax = b $ which implies $$ \\lVert Ax \\rVert= \\lVert b \\rVert$$ By the properties of the induced vector norm this result in the inequality $$ \\lVert b \\rVert\\leq \\lVert A \\rVert \\lVert x \\rVert $$\n",
    "$A \\in \\mathbb R^{n\\times n}$ is invertible. This implies that $A^{-1}$ eksists that satisfies $ x = A^{-1} b$. Taking the norm of each side results in $$ \\lVert x \\rVert= \\lVert {A^{-1}} b \\rVert \\leq \\lVert {A^{-1}}\\rVert \\lVert b \\rVert$$ by property of an induced vector norm. Because of linearity $ Ax = b $ implies that $ A\\delta x = \\delta b$, and the exact same derivation gives $$ \\lVert \\delta x \\rVert= \\lVert {A^{-1}} \\delta b \\rVert \\leq \\lVert {A^{-1}}\\rVert \\lVert \\delta b \\rVert$$ and $$ \\lVert \\delta b \\rVert \\leq \\lVert A \\rVert \\lVert \\delta x \\rVert$$\n",
    "\n",
    "The following inequalitie $\\frac{\\lVert\\delta x \\rVert}{\\lVert \\delta b\\rVert} \\leq \\lVert {A^{-1}} \\rVert$ directly follows from the next to last derived inequality.\n",
    "\n",
    "To get the last result we need to multyply LHS by $\\frac{\\lVert b \\rVert}{\\lVert x \\rVert} $ and RHS by $ \\lVert {A} \\rVert$, which keeps the inequality valid because of the relation $\\frac{\\lVert b \\rVert}{\\lVert x \\rVert} \\leq \\lVert {A} \\rVert$, since something smaller times something smaller must be less than something bigger times som factor also bigger.\n",
    "This results in the equation $\\frac{\\lVert\\delta x \\rVert / \\lVert x\\rVert}{\\lVert \\delta b\\rVert / \\lVert b \\rVert } \\leq K(b) = \\lVert {A^{-1}} \\rVert \\lVert A \\rVert$\n",
    "\n",
    "With $\\lVert A \\rVert = \\lambda_1 (A)$ and $\\lVert A^{-1} \\rVert = 1 / \\lambda_n (A)$ with $\\lambda_1 (A)$ and $\\lambda_n (A)$ being the being the biggest and smallest eigenvalue of A. This results in the equation $\\frac{\\lVert\\delta x \\rVert / \\lVert x\\rVert}{\\lVert \\delta b\\rVert / \\lVert b \\rVert } \\leq K(b) = \\frac{\\lVert \\lambda_1 (A) \\rVert }{\\lVert \\lambda_n (A) \\rVert }$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Because Ax = b, then (A + dA)(x+dx) = b+db means Adx + dAx + dAdx = db. dAdx is presumed small compared to dAx and Adx, so we get the equation Adx + dAx = db. More of this task is not done in this assignment due to difficulty and time, hope the rest of this assignment is done satisfactory enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as lng\n",
    "np.set_printoptions(precision=3)\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.5, -0.5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,1],[1.0004,1]])\n",
    "b = np.array([2,2])\n",
    "delta_b = np.array([2,2.001])\n",
    "lng.solve(A,delta_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compute the LU factorisation with pivoting of a matrix $A$\n",
    "\n",
    "$$\n",
    "     PA = LU\n",
    "$$\n",
    "\n",
    "where $P$ is a permutation matrix, $L$ is a lower-triangular matrix with unit diagonal, and $U$ is an upper-triangular matrix.\n",
    "We represent the matrices in question as follows:\n",
    "The permutation matrix $P$ is $n\\times n$, but is represented as a vector $\\mathtt{P}$ such that row number $k$ in $P$ is the canonical unit vector $e_{\\mathtt{P}_k}$. Let us illustrate this by an example\n",
    "\n",
    "$$\n",
    "\\mathtt{P}=\n",
    "\\left[\n",
    "\\begin{array}{r} 3 \\\\ 1 \\\\ 2 \\end{array}\n",
    "\\right]\\quad\\Rightarrow\\quad\n",
    "P=\\left[\n",
    "\\begin{array}{ccc}\n",
    "0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "We stipulate that a Python function takes a two-dimensional numpy-array $\\mathtt{A}$ as input, and returns\n",
    "an *over-written* $\\mathtt{A}$ which contains $L$ and $U$ in the following sense upon return:\n",
    "x\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\mathtt{A}[\\mathtt{P}[i],j] = L_{ij} & \\text{for}\\ i<j \\\\\n",
    "\\mathtt{A}[\\mathtt{P}[i],j] = U_{ij} & \\text{for}\\ i\\geq j\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "That $L$ has 1 on the diagonal is always the case, so the diagonal of $L$ needs not be stored. The remaining elements of $L$ and $U$ are zero and need not be stored either. The algorithm can be formulated as follows (compare to text book):\n",
    "\n",
    "- Input: $A$ of size $n\\times n$\n",
    "- Initialisation\n",
    "    * Let $P_i = i,\\ i=0,\\ldots,n-1$ be a vector (array) with $n$ components\n",
    "- for $k$ **in** range(n-1):\n",
    "    1. Find index $P_\\ell$ such that $|\\mathtt{A}_{P_\\ell,k}|=\\max_{k\\leq i \\leq n-1} |\\mathtt{A}_{P_i,k}|$, i.e. scan column $k$ from the diagonal and down for the largest element in absolute value. \n",
    "    2. Swap $P_k$ by $P_\\ell$.\n",
    "    3. Find multipliers $A_{P_i,k}\\leftarrow \\frac{A_{P_i,k}}{A_{P_k,k}},\\ i=k+1,\\ldots,n-1$.\n",
    "    4. Perform elimination, i.e. $A_{P_i,j}\\leftarrow A_{P_i,j}-A_{P_i,k}\\cdot A_{P_k,j},\\ i,j=k+1,\\ldots,n-1$\n",
    "- Output: A,P\n",
    "\n",
    "There are – of course – implementations of these, often highly optimised for special cases (e.g. when $A$ is sparse) but here we first want to learn how to code it ourselves. Let's also use this to our advantage\n",
    "\n",
    "\n",
    "1. Write a function for LU-factorisation with row-wise pivoting as indicated above.\n",
    "   A template could be\n",
    "\n",
    "       def mylu(A):\n",
    "   \n",
    "    \n",
    "   and it should return the pivot vector (permutation vector) $\\mathtt{P}$, and over-written  version of $A$. You can also choose to copy $A$ into some other matrix $\\mathtt{LU}$ from the beginning using e.g. \n",
    "\n",
    "       LU = A.copy()\n",
    "\n",
    "2. use the function `scipy.linalg.lu` to test your implementation from the first part. Write a test function\n",
    "\n",
    "       def mylutest(A)\n",
    "   \n",
    "   that compares the result of your implementation to the one from `SciPy`. Call this function for example with\n",
    "\n",
    "   $$\n",
    "   A = \\begin{pmatrix} 2 & 5 & 8 & 7\\\\ 5 & 2 & 2 & 8 \\\\ 7 & 5 & 6 & 6\\\\ 5 & 4 & 4 & 8\\end{pmatrix}\n",
    "   $$\n",
    "   \n",
    "   (or `np.array([[2, 5, 8, 7], [5, 2, 2, 8], [7, 5, 6, 6], [5, 4, 4, 8]])` to easier copy it).\n",
    "   \n",
    "3. Test your function with a matrix `A` that does not meet our assumption of having full rank, for example by repeating a column. What happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_lower = np.array([[2, 0,0,0], [5, 2, 0,0], [7, 5, 6, 0], [5, 4, 4, 8]],dtype = \"float\")\n",
    "L_upper = np.transpose(L_lower)\n",
    "A = np.array([[2, 5, 8, 7], [5, 2, 2, 8], [7, 5, 6, 6], [5, 4, 4, 8]],dtype = \"float\")\n",
    "b = np.array([5, 4, 4.0, 2],dtype = \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLU: \n",
      " [[ 0.286  3.571  6.286  5.286]\n",
      " [ 0.714 -0.44  -0.462  7.462]\n",
      " [ 7.     5.     6.     6.   ]\n",
      " [ 0.714  0.12  -1.04   3.08 ]] \n",
      "\n",
      "scipy.linalg: \n",
      "[[ 0.286  3.571  6.286  5.286]\n",
      " [ 0.714 -0.44  -0.462  7.462]\n",
      " [ 7.     5.     6.     6.   ]\n",
      " [ 0.714  0.12  -1.04   3.08 ]]\n"
     ]
    }
   ],
   "source": [
    "def PLU(A_matrix):\n",
    "    LU = A_matrix.copy()\n",
    "    N = len(A[0,:])\n",
    "    P = np.arange(0,N)\n",
    "    for k in range(N-1):\n",
    "        \n",
    "        #Permutation part\n",
    "        sup_elem, key_elem = 0,0\n",
    "        for i in range(k,N):\n",
    "            if abs(LU[P[i]][k]) > sup_elem:\n",
    "                sup_elem, key_elem = abs(LU[P[i]][k]),i\n",
    "        P[[k,key_elem]] = P[[key_elem,k]]   \n",
    "            \n",
    "        #Elimination part\n",
    "        for i in range(k+1,N):            \n",
    "            LU[P[i],k] = LU[P[i],k]/LU[P[k],k]\n",
    "        for i in range(k+1,N):\n",
    "            for j in range(k+1,N):\n",
    "                LU[P[i],j] -= LU[P[i],k]*LU[P[k],j]\n",
    "    \n",
    "    return LU,P\n",
    "\n",
    "# print(A)        \n",
    "LU,P = PLU(A)\n",
    "print(\"PLU: \\n\",LU,'\\n')\n",
    "LU2 = lng.lu(A)\n",
    "print(f'scipy.linalg: \\n{LU2[0]@((LU2[1] + LU2[2] - np.identity(len(LU2[2]))))}')\n",
    "P, L, U = lng.lu(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "1. Implement a\n",
    "\n",
    "  `def forward_substitution(A,b):`\n",
    "    \n",
    "  function that takes a lower triangular matrix `A` and some vector `b` to solve $A\\mathbf{x} = \\mathbf{b}$\n",
    "\n",
    "2. Implement a\n",
    "\n",
    "  `def backward_substitution(A,b):` \n",
    "        \n",
    "  function that takes an upper triangualr matrix `A` and some vector `b` to solve $A\\mathbf{x} = \\mathbf{b}$ for this case.\n",
    "  \n",
    "3. Combine the last two parts with Problem 2 and implement a function\n",
    "\n",
    "   `def my_solve(A,b):`\n",
    "\n",
    "   for a square matrix `A` and a right hand side `b` that computes the LU decomposition of `A` and then uses the first two parts of this problem to compute the solution to $A\\mathbf{x} = \\mathbf{b}$\n",
    "   \n",
    "4. Performance. Let's compare our implementation for two cases as well as to the original. To be precise\n",
    "  * fix some $n$, say `n=100`\n",
    "  * generate a reguar square matrix `A` (Hint: maybe create `L` and `U` here to be sure `A` is regular)\n",
    "  * generate `m`, say `m=200` right hand sides `b_k`\n",
    "  * run an experiment where you time\n",
    "\n",
    "      a) calling `m` times `my_solve(A,b)` once for each `b_k`\n",
    "\n",
    "      b) only computing the LU decomposition once and use backward and forward substitutions `m` times\n",
    "\n",
    "      c) using `np.linalg.solve`\n",
    "      \n",
    "    Where do the time differences from a) to b) come from and where the ones from c) to b)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_subtitution(A,b):\n",
    "    N = len(b)\n",
    "    c = np.copy(b)\n",
    "    A = A.copy()\n",
    "    x = np.zeros(len(b))\n",
    "    x[0] = c[0]\n",
    "    for i in range(1,N):\n",
    "        sums = 0\n",
    "        for j in range(0,i):\n",
    "            sums += A[i][j]*x[j]\n",
    "        x[i] = (c[i] - sums)/A[i][i]\n",
    "    return c\n",
    "\n",
    "\n",
    "def backward_subtitution(A,b):\n",
    "    N = len(b)\n",
    "    c = np.copy(b)\n",
    "    A = A.copy()\n",
    "    x = np.zeros(len(b))\n",
    "    for i in range(N-1,-1,-1):\n",
    "        sums = 0\n",
    "        for j in range(N-1,i,-1):\n",
    "            sums += A[i][j]*c[j]\n",
    "        x[i] = (c[i] - sums)/A[i][i]\n",
    "    return x\n",
    "        \n",
    "def my_solve(A,b):\n",
    "    N = len(A[0,:])\n",
    "    LU, P = PLU(A)\n",
    "    b = b.copy()\n",
    "    \n",
    "    L = LU.copy()\n",
    "    U = LU.copy()\n",
    "    for i in range(N):\n",
    "        L[i,i] = 1\n",
    "        for j in range(N):\n",
    "            if j>i:\n",
    "                L[i][j] = 0\n",
    "            if i>j:\n",
    "                U[i][j] = 0\n",
    "    Pmatrix = np.zeros((N,N))\n",
    "    for i,val in enumerate(P):\n",
    "        Pmatrix[i,val] = 1\n",
    "    c =  forward_subtitution(L, np.transpose(Pmatrix)@b)\n",
    "    x = backward_subtitution(U, c)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-120.5     40.734   -2.833    0.974] \n",
      "\n",
      "[-0.165  2.464 -1.464  0.103]\n"
     ]
    }
   ],
   "source": [
    "b = np.array([1.0,2.0,3.0,4.0],dtype = 'float')\n",
    "sol1 = my_solve(A,b)\n",
    "sol2 = np.linalg.solve(A,b)\n",
    "\n",
    "print(sol1,'\\n')\n",
    "print(sol2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just cant seem to be able to make this one work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "m = 200\n",
    "\n",
    "L = np.zeros((n,n))\n",
    "U = np.zeros((n,n))\n",
    "for i in range(n):\n",
    "    L[i] = np.random.rand(n)\n",
    "    U[i] = np.random.rand(n)\n",
    "A = np.tril(L)@np.transpose(np.tril(U))\n",
    "bks = np.zeros((m,n))\n",
    "for i in range(m):\n",
    "    bks[i] = np.random.rand(n)\n",
    "    \n",
    "sol1, sol2, sol3 = np.zeros((m,n)), np.zeros((m,n)), np.zeros((m,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling my solve m times\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "for i in range(m):\n",
    "    sol1[i] = my_solve(A.copy(),bks[i].copy())\n",
    "    \n",
    "#####################################################\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling LU 1 time and using forward/backwards m times\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "LU, P = PLU(A)\n",
    "N = len(A[0,:])\n",
    "L = LU.copy()\n",
    "U = LU.copy()\n",
    "for i in range(N):\n",
    "    L[i,i] = 1\n",
    "    for j in range(N):\n",
    "        if j>i:\n",
    "            L[i][j] = 0\n",
    "        if i>j:\n",
    "            U[i][j] = 0\n",
    "Pmatrix = np.zeros((N,N))\n",
    "for i,val in enumerate(P):\n",
    "    Pmatrix[i,val] = 1\n",
    "for i in range(m):\n",
    "    c =  forward_subtitution(L, np.transpose(Pmatrix)@bks[i].copy())\n",
    "    x = backward_subtitution(U, c)\n",
    "    sol2[i] = x\n",
    "    \n",
    "#####################################################\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling linalg.solve m times\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "for i in range(m):\n",
    "    sol3[i] = np.linalg.solve(A.copy(),bks[i].copy())\n",
    "    \n",
    "#####################################################\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(sol1 - sol3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(sol1 - sol2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.linalg.norm(sol2 - sol3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(sol3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My solver somewhere got something wrong, which gives the wrong ansewer. The runtime should not however be affected by this, as my algorithms got the same complexity as supposed to when done right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the LU factorysation 1 time obviously save a lot of time over doing it m times, particularly when the timecomplexity of the solver is decided by the LU-algorithms O(n^3), and not the forward and backward solver which is O(n^2). How the np.linalg.solve solves as fast as it does I have not found a convincing answer for. It seems really fast."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
